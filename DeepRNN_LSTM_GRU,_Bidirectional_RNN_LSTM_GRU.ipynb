{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPce2ZlLGrsS"
      },
      "outputs": [],
      "source": [
        "my_paragraph = \"\"\"About the Program\n",
        "What is the total duration of the course?\n",
        "The total duration of the course is 16 months.\n",
        "What is the syllabus of the mentorship program?\n",
        "We will be covering the following modules:\n",
        "Python Fundamentals\n",
        "Python libraries for Data Science\n",
        "Data Analysis\n",
        "SQL for Data Science\n",
        "Maths for Machine Learning\n",
        "ML Algorithms\n",
        "Deep Learning with NLP\n",
        "Advance Deep Learning with Generative AI\n",
        "Practical ML\n",
        "MLOPs\n",
        "Case studies\n",
        "Will Deep Learning and NLP be a part of this program?\n",
        "No, NLP and Deep Learning both are not a part of this program’s curriculum.\n",
        "What if I miss a live session? Will I get a recording of the session?\n",
        "Yes all our sessions are recorded, so even if you miss a session you can go back and watch the recording.\n",
        "Where can I find the class schedule?\n",
        "Checkout this google sheet to see month by month time table of the course\n",
        "What is the time duration of all the live sessions?\n",
        "Roughly, all the sessions last 3.5 hours.\n",
        "What is the language spoken by the instructor during the sessions?\n",
        "English\n",
        "How will I be informed about the upcoming class?\n",
        "You will get a mail from our side before every weekend session.\n",
        "Can I do this course if I am from a non-tech background?\n",
        "Yes, absolutely.\n",
        "I am late, can I join the program in the middle?\n",
        "Absolutely, you can join the program anytime.\n",
        "If I join/pay in the middle, will I be able to see all the past lectures?\n",
        "Yes, once you make the payment you will be able to see all the past content in your dashboard.\n",
        "Where do I have to submit the task?\n",
        "You don’t have to submit the task. We will provide you with the solutions, you have to self evaluate the task yourself.\n",
        "Will we do case studies in the program?\n",
        "Yes.\n",
        "Where can we contact you?\n",
        "You can mail us at abc@learnbay.com\n",
        "You have to make all your monthly payments on our website. Here is the link for our website - https://learnwith.Learnbay.in/\n",
        "Where can I reach out in case of a doubt after the session?\n",
        "You will have to fill a google form provided in your dashboard and our team will contact you for a 1 on 1 doubt clearance session\n",
        "If I join the program late, can I still ask past week doubts?\n",
        "Yes, just select past week doubt in the doubt clearance google form.\n",
        "Certificate and Placement Assistance related queries\n",
        "What is the criteria to get the certificate?\n",
        "There are 2 criterias:\n",
        "You have to pay the entire fee\n",
        "You have to attempt all the course assessments.\n",
        "Portfolio Building sessions\n",
        "Soft skill sessions\n",
        "Sessions with industry mentors\n",
        "Discussion on Job hunting strategies\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_paragraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "HYEPbuVrHKkh",
        "outputId": "28a37d3d-3e18-4e93-e432-c9cde35fffd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'About the Program\\nWhat is the total duration of the course?\\nThe total duration of the course is 16 months.\\nWhat is the syllabus of the mentorship program?\\nWe will be covering the following modules:\\nPython Fundamentals\\nPython libraries for Data Science\\nData Analysis\\nSQL for Data Science\\nMaths for Machine Learning\\nML Algorithms\\nDeep Learning with NLP\\nAdvance Deep Learning with Generative AI\\nPractical ML\\nMLOPs\\nCase studies\\nWill Deep Learning and NLP be a part of this program?\\nNo, NLP and Deep Learning both are not a part of this program’s curriculum.\\nWhat if I miss a live session? Will I get a recording of the session?\\nYes all our sessions are recorded, so even if you miss a session you can go back and watch the recording.\\nWhere can I find the class schedule?\\nCheckout this google sheet to see month by month time table of the course\\nWhat is the time duration of all the live sessions?\\nRoughly, all the sessions last 3.5 hours.\\nWhat is the language spoken by the instructor during the sessions?\\nEnglish\\nHow will I be informed about the upcoming class?\\nYou will get a mail from our side before every weekend session.\\nCan I do this course if I am from a non-tech background?\\nYes, absolutely.\\nI am late, can I join the program in the middle?\\nAbsolutely, you can join the program anytime.\\nIf I join/pay in the middle, will I be able to see all the past lectures?\\nYes, once you make the payment you will be able to see all the past content in your dashboard.\\nWhere do I have to submit the task?\\nYou don’t have to submit the task. We will provide you with the solutions, you have to self evaluate the task yourself.\\nWill we do case studies in the program?\\nYes.\\nWhere can we contact you?\\nYou can mail us at abc@learnbay.com\\nYou have to make all your monthly payments on our website. Here is the link for our website - https://learnwith.Learnbay.in/\\nWhere can I reach out in case of a doubt after the session?\\nYou will have to fill a google form provided in your dashboard and our team will contact you for a 1 on 1 doubt clearance session\\nIf I join the program late, can I still ask past week doubts?\\nYes, just select past week doubt in the doubt clearance google form.\\nCertificate and Placement Assistance related queries\\nWhat is the criteria to get the certificate?\\nThere are 2 criterias:\\nYou have to pay the entire fee\\nYou have to attempt all the course assessments.\\nPortfolio Building sessions\\nSoft skill sessions\\nSessions with industry mentors\\nDiscussion on Job hunting strategies'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "_Tx7f6m3HKn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([my_paragraph])"
      ],
      "metadata": {
        "id": "QmGpDsvvHVyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRcvNkirHKrA",
        "outputId": "9eb30213-2af2-43ec-aefc-061b6fd3eaa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "186"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "\n",
        "for sentence in my_paragraph.split('\\n'):\n",
        "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for i in range(1, len(tokenized_sentence)):\n",
        "    input_sequences.append(tokenized_sentence[:i+1])\n"
      ],
      "metadata": {
        "id": "3YAgoaoZHKuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4E4KOJ1HKxR",
        "outputId": "fba088d0-da49-4f8a-9d0b-4ad7e4f773b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[45, 1],\n",
              " [45, 1, 10],\n",
              " [15, 11],\n",
              " [15, 11, 1],\n",
              " [15, 11, 1, 46],\n",
              " [15, 11, 1, 46, 33],\n",
              " [15, 11, 1, 46, 33, 7],\n",
              " [15, 11, 1, 46, 33, 7, 1],\n",
              " [15, 11, 1, 46, 33, 7, 1, 17],\n",
              " [1, 46],\n",
              " [1, 46, 33],\n",
              " [1, 46, 33, 7],\n",
              " [1, 46, 33, 7, 1],\n",
              " [1, 46, 33, 7, 1, 17],\n",
              " [1, 46, 33, 7, 1, 17, 11],\n",
              " [1, 46, 33, 7, 1, 17, 11, 78],\n",
              " [1, 46, 33, 7, 1, 17, 11, 78, 79],\n",
              " [15, 11],\n",
              " [15, 11, 1],\n",
              " [15, 11, 1, 80],\n",
              " [15, 11, 1, 80, 7],\n",
              " [15, 11, 1, 80, 7, 1],\n",
              " [15, 11, 1, 80, 7, 1, 81],\n",
              " [15, 11, 1, 80, 7, 1, 81, 10],\n",
              " [25, 4],\n",
              " [25, 4, 18],\n",
              " [25, 4, 18, 82],\n",
              " [25, 4, 18, 82, 1],\n",
              " [25, 4, 18, 82, 1, 83],\n",
              " [25, 4, 18, 82, 1, 83, 84],\n",
              " [47, 85],\n",
              " [47, 86],\n",
              " [47, 86, 19],\n",
              " [47, 86, 19, 34],\n",
              " [47, 86, 19, 34, 48],\n",
              " [34, 87],\n",
              " [88, 19],\n",
              " [88, 19, 34],\n",
              " [88, 19, 34, 48],\n",
              " [89, 19],\n",
              " [89, 19, 90],\n",
              " [89, 19, 90, 20],\n",
              " [49, 91],\n",
              " [26, 20],\n",
              " [26, 20, 27],\n",
              " [26, 20, 27, 35],\n",
              " [92, 26],\n",
              " [92, 26, 20],\n",
              " [92, 26, 20, 27],\n",
              " [92, 26, 20, 27, 93],\n",
              " [92, 26, 20, 27, 93, 94],\n",
              " [95, 49],\n",
              " [36, 50],\n",
              " [4, 26],\n",
              " [4, 26, 20],\n",
              " [4, 26, 20, 21],\n",
              " [4, 26, 20, 21, 35],\n",
              " [4, 26, 20, 21, 35, 18],\n",
              " [4, 26, 20, 21, 35, 18, 6],\n",
              " [4, 26, 20, 21, 35, 18, 6, 51],\n",
              " [4, 26, 20, 21, 35, 18, 6, 51, 7],\n",
              " [4, 26, 20, 21, 35, 18, 6, 51, 7, 28],\n",
              " [4, 26, 20, 21, 35, 18, 6, 51, 7, 28, 10],\n",
              " [97, 35],\n",
              " [97, 35, 21],\n",
              " [97, 35, 21, 26],\n",
              " [97, 35, 21, 26, 20],\n",
              " [97, 35, 21, 26, 20, 98],\n",
              " [97, 35, 21, 26, 20, 98, 37],\n",
              " [97, 35, 21, 26, 20, 98, 37, 99],\n",
              " [97, 35, 21, 26, 20, 98, 37, 99, 6],\n",
              " [97, 35, 21, 26, 20, 98, 37, 99, 6, 51],\n",
              " [97, 35, 21, 26, 20, 98, 37, 99, 6, 51, 7],\n",
              " [97, 35, 21, 26, 20, 98, 37, 99, 6, 51, 7, 28],\n",
              " [97, 35, 21, 26, 20, 98, 37, 99, 6, 51, 7, 28, 100],\n",
              " [97, 35, 21, 26, 20, 98, 37, 99, 6, 51, 7, 28, 100, 101],\n",
              " [15, 22],\n",
              " [15, 22, 3],\n",
              " [15, 22, 3, 52],\n",
              " [15, 22, 3, 52, 6],\n",
              " [15, 22, 3, 52, 6, 53],\n",
              " [15, 22, 3, 52, 6, 53, 16],\n",
              " [15, 22, 3, 52, 6, 53, 16, 4],\n",
              " [15, 22, 3, 52, 6, 53, 16, 4, 3],\n",
              " [15, 22, 3, 52, 6, 53, 16, 4, 3, 38],\n",
              " [15, 22, 3, 52, 6, 53, 16, 4, 3, 38, 6],\n",
              " [15, 22, 3, 52, 6, 53, 16, 4, 3, 38, 6, 54],\n",
              " [15, 22, 3, 52, 6, 53, 16, 4, 3, 38, 6, 54, 7],\n",
              " [15, 22, 3, 52, 6, 53, 16, 4, 3, 38, 6, 54, 7, 1],\n",
              " [15, 22, 3, 52, 6, 53, 16, 4, 3, 38, 6, 54, 7, 1, 16],\n",
              " [23, 12],\n",
              " [23, 12, 24],\n",
              " [23, 12, 24, 13],\n",
              " [23, 12, 24, 13, 37],\n",
              " [23, 12, 24, 13, 37, 102],\n",
              " [23, 12, 24, 13, 37, 102, 103],\n",
              " [23, 12, 24, 13, 37, 102, 103, 104],\n",
              " [23, 12, 24, 13, 37, 102, 103, 104, 22],\n",
              " [23, 12, 24, 13, 37, 102, 103, 104, 22, 2],\n",
              " [23, 12, 24, 13, 37, 102, 103, 104, 22, 2, 52],\n",
              " [23, 12, 24, 13, 37, 102, 103, 104, 22, 2, 52, 6],\n",
              " [23, 12, 24, 13, 37, 102, 103, 104, 22, 2, 52, 6, 16],\n",
              " [23, 12, 24, 13, 37, 102, 103, 104, 22, 2, 52, 6, 16, 2],\n",
              " [23, 12, 24, 13, 37, 102, 103, 104, 22, 2, 52, 6, 16, 2, 8],\n",
              " [23, 12, 24, 13, 37, 102, 103, 104, 22, 2, 52, 6, 16, 2, 8, 105],\n",
              " [23, 12, 24, 13, 37, 102, 103, 104, 22, 2, 52, 6, 16, 2, 8, 105, 106],\n",
              " [23, 12, 24, 13, 37, 102, 103, 104, 22, 2, 52, 6, 16, 2, 8, 105, 106, 21],\n",
              " [23,\n",
              "  12,\n",
              "  24,\n",
              "  13,\n",
              "  37,\n",
              "  102,\n",
              "  103,\n",
              "  104,\n",
              "  22,\n",
              "  2,\n",
              "  52,\n",
              "  6,\n",
              "  16,\n",
              "  2,\n",
              "  8,\n",
              "  105,\n",
              "  106,\n",
              "  21,\n",
              "  107],\n",
              " [23,\n",
              "  12,\n",
              "  24,\n",
              "  13,\n",
              "  37,\n",
              "  102,\n",
              "  103,\n",
              "  104,\n",
              "  22,\n",
              "  2,\n",
              "  52,\n",
              "  6,\n",
              "  16,\n",
              "  2,\n",
              "  8,\n",
              "  105,\n",
              "  106,\n",
              "  21,\n",
              "  107,\n",
              "  1],\n",
              " [23,\n",
              "  12,\n",
              "  24,\n",
              "  13,\n",
              "  37,\n",
              "  102,\n",
              "  103,\n",
              "  104,\n",
              "  22,\n",
              "  2,\n",
              "  52,\n",
              "  6,\n",
              "  16,\n",
              "  2,\n",
              "  8,\n",
              "  105,\n",
              "  106,\n",
              "  21,\n",
              "  107,\n",
              "  1,\n",
              "  54],\n",
              " [29, 8],\n",
              " [29, 8, 3],\n",
              " [29, 8, 3, 108],\n",
              " [29, 8, 3, 108, 1],\n",
              " [29, 8, 3, 108, 1, 55],\n",
              " [29, 8, 3, 108, 1, 55, 109],\n",
              " [110, 28],\n",
              " [110, 28, 39],\n",
              " [110, 28, 39, 111],\n",
              " [110, 28, 39, 111, 5],\n",
              " [110, 28, 39, 111, 5, 40],\n",
              " [110, 28, 39, 111, 5, 40, 56],\n",
              " [110, 28, 39, 111, 5, 40, 56, 57],\n",
              " [110, 28, 39, 111, 5, 40, 56, 57, 56],\n",
              " [110, 28, 39, 111, 5, 40, 56, 57, 56, 58],\n",
              " [110, 28, 39, 111, 5, 40, 56, 57, 56, 58, 112],\n",
              " [110, 28, 39, 111, 5, 40, 56, 57, 56, 58, 112, 7],\n",
              " [110, 28, 39, 111, 5, 40, 56, 57, 56, 58, 112, 7, 1],\n",
              " [110, 28, 39, 111, 5, 40, 56, 57, 56, 58, 112, 7, 1, 17],\n",
              " [15, 11],\n",
              " [15, 11, 1],\n",
              " [15, 11, 1, 58],\n",
              " [15, 11, 1, 58, 33],\n",
              " [15, 11, 1, 58, 33, 7],\n",
              " [15, 11, 1, 58, 33, 7, 12],\n",
              " [15, 11, 1, 58, 33, 7, 12, 1],\n",
              " [15, 11, 1, 58, 33, 7, 12, 1, 53],\n",
              " [15, 11, 1, 58, 33, 7, 12, 1, 53, 13],\n",
              " [113, 12],\n",
              " [113, 12, 1],\n",
              " [113, 12, 1, 13],\n",
              " [113, 12, 1, 13, 114],\n",
              " [113, 12, 1, 13, 114, 115],\n",
              " [113, 12, 1, 13, 114, 115, 116],\n",
              " [113, 12, 1, 13, 114, 115, 116, 117],\n",
              " [15, 11],\n",
              " [15, 11, 1],\n",
              " [15, 11, 1, 118],\n",
              " [15, 11, 1, 118, 119],\n",
              " [15, 11, 1, 118, 119, 57],\n",
              " [15, 11, 1, 118, 119, 57, 1],\n",
              " [15, 11, 1, 118, 119, 57, 1, 120],\n",
              " [15, 11, 1, 118, 119, 57, 1, 120, 121],\n",
              " [15, 11, 1, 118, 119, 57, 1, 120, 121, 1],\n",
              " [15, 11, 1, 118, 119, 57, 1, 120, 121, 1, 13],\n",
              " [123, 4],\n",
              " [123, 4, 3],\n",
              " [123, 4, 3, 18],\n",
              " [123, 4, 3, 18, 124],\n",
              " [123, 4, 3, 18, 124, 45],\n",
              " [123, 4, 3, 18, 124, 45, 1],\n",
              " [123, 4, 3, 18, 124, 45, 1, 125],\n",
              " [123, 4, 3, 18, 124, 45, 1, 125, 55],\n",
              " [2, 4],\n",
              " [2, 4, 38],\n",
              " [2, 4, 38, 6],\n",
              " [2, 4, 38, 6, 59],\n",
              " [2, 4, 38, 6, 59, 60],\n",
              " [2, 4, 38, 6, 59, 60, 24],\n",
              " [2, 4, 38, 6, 59, 60, 24, 126],\n",
              " [2, 4, 38, 6, 59, 60, 24, 126, 127],\n",
              " [2, 4, 38, 6, 59, 60, 24, 126, 127, 128],\n",
              " [2, 4, 38, 6, 59, 60, 24, 126, 127, 128, 129],\n",
              " [2, 4, 38, 6, 59, 60, 24, 126, 127, 128, 129, 16],\n",
              " [8, 3],\n",
              " [8, 3, 41],\n",
              " [8, 3, 41, 28],\n",
              " [8, 3, 41, 28, 17],\n",
              " [8, 3, 41, 28, 17, 22],\n",
              " [8, 3, 41, 28, 17, 22, 3],\n",
              " [8, 3, 41, 28, 17, 22, 3, 61],\n",
              " [8, 3, 41, 28, 17, 22, 3, 61, 60],\n",
              " [8, 3, 41, 28, 17, 22, 3, 61, 60, 6],\n",
              " [8, 3, 41, 28, 17, 22, 3, 61, 60, 6, 130],\n",
              " [8, 3, 41, 28, 17, 22, 3, 61, 60, 6, 130, 131],\n",
              " [8, 3, 41, 28, 17, 22, 3, 61, 60, 6, 130, 131, 132],\n",
              " [23, 62],\n",
              " [3, 61],\n",
              " [3, 61, 63],\n",
              " [3, 61, 63, 8],\n",
              " [3, 61, 63, 8, 3],\n",
              " [3, 61, 63, 8, 3, 30],\n",
              " [3, 61, 63, 8, 3, 30, 1],\n",
              " [3, 61, 63, 8, 3, 30, 1, 10],\n",
              " [3, 61, 63, 8, 3, 30, 1, 10, 9],\n",
              " [3, 61, 63, 8, 3, 30, 1, 10, 9, 1],\n",
              " [3, 61, 63, 8, 3, 30, 1, 10, 9, 1, 64],\n",
              " [62, 2],\n",
              " [62, 2, 8],\n",
              " [62, 2, 8, 30],\n",
              " [62, 2, 8, 30, 1],\n",
              " [62, 2, 8, 30, 1, 10],\n",
              " [62, 2, 8, 30, 1, 10, 133],\n",
              " [22, 3],\n",
              " [22, 3, 30],\n",
              " [22, 3, 30, 65],\n",
              " [22, 3, 30, 65, 9],\n",
              " [22, 3, 30, 65, 9, 1],\n",
              " [22, 3, 30, 65, 9, 1, 64],\n",
              " [22, 3, 30, 65, 9, 1, 64, 4],\n",
              " [22, 3, 30, 65, 9, 1, 64, 4, 3],\n",
              " [22, 3, 30, 65, 9, 1, 64, 4, 3, 18],\n",
              " [22, 3, 30, 65, 9, 1, 64, 4, 3, 18, 66],\n",
              " [22, 3, 30, 65, 9, 1, 64, 4, 3, 18, 66, 5],\n",
              " [22, 3, 30, 65, 9, 1, 64, 4, 3, 18, 66, 5, 40],\n",
              " [22, 3, 30, 65, 9, 1, 64, 4, 3, 18, 66, 5, 40, 12],\n",
              " [22, 3, 30, 65, 9, 1, 64, 4, 3, 18, 66, 5, 40, 12, 1],\n",
              " [22, 3, 30, 65, 9, 1, 64, 4, 3, 18, 66, 5, 40, 12, 1, 31],\n",
              " [22, 3, 30, 65, 9, 1, 64, 4, 3, 18, 66, 5, 40, 12, 1, 31, 134],\n",
              " [23, 135],\n",
              " [23, 135, 2],\n",
              " [23, 135, 2, 67],\n",
              " [23, 135, 2, 67, 1],\n",
              " [23, 135, 2, 67, 1, 136],\n",
              " [23, 135, 2, 67, 1, 136, 2],\n",
              " [23, 135, 2, 67, 1, 136, 2, 4],\n",
              " [23, 135, 2, 67, 1, 136, 2, 4, 18],\n",
              " [23, 135, 2, 67, 1, 136, 2, 4, 18, 66],\n",
              " [23, 135, 2, 67, 1, 136, 2, 4, 18, 66, 5],\n",
              " [23, 135, 2, 67, 1, 136, 2, 4, 18, 66, 5, 40],\n",
              " [23, 135, 2, 67, 1, 136, 2, 4, 18, 66, 5, 40, 12],\n",
              " [23, 135, 2, 67, 1, 136, 2, 4, 18, 66, 5, 40, 12, 1],\n",
              " [23, 135, 2, 67, 1, 136, 2, 4, 18, 66, 5, 40, 12, 1, 31],\n",
              " [23, 135, 2, 67, 1, 136, 2, 4, 18, 66, 5, 40, 12, 1, 31, 137],\n",
              " [23, 135, 2, 67, 1, 136, 2, 4, 18, 66, 5, 40, 12, 1, 31, 137, 9],\n",
              " [23, 135, 2, 67, 1, 136, 2, 4, 18, 66, 5, 40, 12, 1, 31, 137, 9, 42],\n",
              " [23, 135, 2, 67, 1, 136, 2, 4, 18, 66, 5, 40, 12, 1, 31, 137, 9, 42, 68],\n",
              " [29, 41],\n",
              " [29, 41, 3],\n",
              " [29, 41, 3, 14],\n",
              " [29, 41, 3, 14, 5],\n",
              " [29, 41, 3, 14, 5, 69],\n",
              " [29, 41, 3, 14, 5, 69, 1],\n",
              " [29, 41, 3, 14, 5, 69, 1, 43],\n",
              " [2, 138],\n",
              " [2, 138, 14],\n",
              " [2, 138, 14, 5],\n",
              " [2, 138, 14, 5, 69],\n",
              " [2, 138, 14, 5, 69, 1],\n",
              " [2, 138, 14, 5, 69, 1, 43],\n",
              " [2, 138, 14, 5, 69, 1, 43, 25],\n",
              " [2, 138, 14, 5, 69, 1, 43, 25, 4],\n",
              " [2, 138, 14, 5, 69, 1, 43, 25, 4, 139],\n",
              " [2, 138, 14, 5, 69, 1, 43, 25, 4, 139, 2],\n",
              " [2, 138, 14, 5, 69, 1, 43, 25, 4, 139, 2, 27],\n",
              " [2, 138, 14, 5, 69, 1, 43, 25, 4, 139, 2, 27, 1],\n",
              " [2, 138, 14, 5, 69, 1, 43, 25, 4, 139, 2, 27, 1, 140],\n",
              " [2, 138, 14, 5, 69, 1, 43, 25, 4, 139, 2, 27, 1, 140, 2],\n",
              " [2, 138, 14, 5, 69, 1, 43, 25, 4, 139, 2, 27, 1, 140, 2, 14],\n",
              " [2, 138, 14, 5, 69, 1, 43, 25, 4, 139, 2, 27, 1, 140, 2, 14, 5],\n",
              " [2, 138, 14, 5, 69, 1, 43, 25, 4, 139, 2, 27, 1, 140, 2, 14, 5, 141],\n",
              " [2, 138, 14, 5, 69, 1, 43, 25, 4, 139, 2, 27, 1, 140, 2, 14, 5, 141, 142],\n",
              " [2, 138, 14, 5, 69, 1, 43, 25, 4, 139, 2, 27, 1, 140, 2, 14, 5, 141, 142, 1],\n",
              " [2,\n",
              "  138,\n",
              "  14,\n",
              "  5,\n",
              "  69,\n",
              "  1,\n",
              "  43,\n",
              "  25,\n",
              "  4,\n",
              "  139,\n",
              "  2,\n",
              "  27,\n",
              "  1,\n",
              "  140,\n",
              "  2,\n",
              "  14,\n",
              "  5,\n",
              "  141,\n",
              "  142,\n",
              "  1,\n",
              "  43],\n",
              " [2,\n",
              "  138,\n",
              "  14,\n",
              "  5,\n",
              "  69,\n",
              "  1,\n",
              "  43,\n",
              "  25,\n",
              "  4,\n",
              "  139,\n",
              "  2,\n",
              "  27,\n",
              "  1,\n",
              "  140,\n",
              "  2,\n",
              "  14,\n",
              "  5,\n",
              "  141,\n",
              "  142,\n",
              "  1,\n",
              "  43,\n",
              "  143],\n",
              " [4, 25],\n",
              " [4, 25, 41],\n",
              " [4, 25, 41, 36],\n",
              " [4, 25, 41, 36, 50],\n",
              " [4, 25, 41, 36, 50, 9],\n",
              " [4, 25, 41, 36, 50, 9, 1],\n",
              " [4, 25, 41, 36, 50, 9, 1, 10],\n",
              " [29, 8],\n",
              " [29, 8, 25],\n",
              " [29, 8, 25, 70],\n",
              " [29, 8, 25, 70, 2],\n",
              " [2, 8],\n",
              " [2, 8, 59],\n",
              " [2, 8, 59, 144],\n",
              " [2, 8, 59, 144, 145],\n",
              " [2, 8, 59, 144, 145, 146],\n",
              " [2, 8, 59, 144, 145, 146, 71],\n",
              " [2, 8, 59, 144, 145, 146, 71, 147],\n",
              " [2, 14],\n",
              " [2, 14, 5],\n",
              " [2, 14, 5, 67],\n",
              " [2, 14, 5, 67, 12],\n",
              " [2, 14, 5, 67, 12, 42],\n",
              " [2, 14, 5, 67, 12, 42, 148],\n",
              " [2, 14, 5, 67, 12, 42, 148, 149],\n",
              " [2, 14, 5, 67, 12, 42, 148, 149, 44],\n",
              " [2, 14, 5, 67, 12, 42, 148, 149, 44, 24],\n",
              " [2, 14, 5, 67, 12, 42, 148, 149, 44, 24, 72],\n",
              " [2, 14, 5, 67, 12, 42, 148, 149, 44, 24, 72, 150],\n",
              " [2, 14, 5, 67, 12, 42, 148, 149, 44, 24, 72, 150, 11],\n",
              " [2, 14, 5, 67, 12, 42, 148, 149, 44, 24, 72, 150, 11, 1],\n",
              " [2, 14, 5, 67, 12, 42, 148, 149, 44, 24, 72, 150, 11, 1, 151],\n",
              " [2, 14, 5, 67, 12, 42, 148, 149, 44, 24, 72, 150, 11, 1, 151, 19],\n",
              " [2, 14, 5, 67, 12, 42, 148, 149, 44, 24, 72, 150, 11, 1, 151, 19, 24],\n",
              " [2, 14, 5, 67, 12, 42, 148, 149, 44, 24, 72, 150, 11, 1, 151, 19, 24, 72],\n",
              " [2,\n",
              "  14,\n",
              "  5,\n",
              "  67,\n",
              "  12,\n",
              "  42,\n",
              "  148,\n",
              "  149,\n",
              "  44,\n",
              "  24,\n",
              "  72,\n",
              "  150,\n",
              "  11,\n",
              "  1,\n",
              "  151,\n",
              "  19,\n",
              "  24,\n",
              "  72,\n",
              "  152],\n",
              " [2,\n",
              "  14,\n",
              "  5,\n",
              "  67,\n",
              "  12,\n",
              "  42,\n",
              "  148,\n",
              "  149,\n",
              "  44,\n",
              "  24,\n",
              "  72,\n",
              "  150,\n",
              "  11,\n",
              "  1,\n",
              "  151,\n",
              "  19,\n",
              "  24,\n",
              "  72,\n",
              "  152,\n",
              "  153],\n",
              " [2,\n",
              "  14,\n",
              "  5,\n",
              "  67,\n",
              "  12,\n",
              "  42,\n",
              "  148,\n",
              "  149,\n",
              "  44,\n",
              "  24,\n",
              "  72,\n",
              "  150,\n",
              "  11,\n",
              "  1,\n",
              "  151,\n",
              "  19,\n",
              "  24,\n",
              "  72,\n",
              "  152,\n",
              "  153,\n",
              "  71],\n",
              " [2,\n",
              "  14,\n",
              "  5,\n",
              "  67,\n",
              "  12,\n",
              "  42,\n",
              "  148,\n",
              "  149,\n",
              "  44,\n",
              "  24,\n",
              "  72,\n",
              "  150,\n",
              "  11,\n",
              "  1,\n",
              "  151,\n",
              "  19,\n",
              "  24,\n",
              "  72,\n",
              "  152,\n",
              "  153,\n",
              "  71,\n",
              "  9],\n",
              " [29, 8],\n",
              " [29, 8, 3],\n",
              " [29, 8, 3, 154],\n",
              " [29, 8, 3, 154, 155],\n",
              " [29, 8, 3, 154, 155, 9],\n",
              " [29, 8, 3, 154, 155, 9, 36],\n",
              " [29, 8, 3, 154, 155, 9, 36, 7],\n",
              " [29, 8, 3, 154, 155, 9, 36, 7, 6],\n",
              " [29, 8, 3, 154, 155, 9, 36, 7, 6, 32],\n",
              " [29, 8, 3, 154, 155, 9, 36, 7, 6, 32, 156],\n",
              " [29, 8, 3, 154, 155, 9, 36, 7, 6, 32, 156, 1],\n",
              " [29, 8, 3, 154, 155, 9, 36, 7, 6, 32, 156, 1, 16],\n",
              " [2, 4],\n",
              " [2, 4, 14],\n",
              " [2, 4, 14, 5],\n",
              " [2, 4, 14, 5, 157],\n",
              " [2, 4, 14, 5, 157, 6],\n",
              " [2, 4, 14, 5, 157, 6, 39],\n",
              " [2, 4, 14, 5, 157, 6, 39, 73],\n",
              " [2, 4, 14, 5, 157, 6, 39, 73, 158],\n",
              " [2, 4, 14, 5, 157, 6, 39, 73, 158, 9],\n",
              " [2, 4, 14, 5, 157, 6, 39, 73, 158, 9, 42],\n",
              " [2, 4, 14, 5, 157, 6, 39, 73, 158, 9, 42, 68],\n",
              " [2, 4, 14, 5, 157, 6, 39, 73, 158, 9, 42, 68, 21],\n",
              " [2, 4, 14, 5, 157, 6, 39, 73, 158, 9, 42, 68, 21, 24],\n",
              " [2, 4, 14, 5, 157, 6, 39, 73, 158, 9, 42, 68, 21, 24, 159],\n",
              " [2, 4, 14, 5, 157, 6, 39, 73, 158, 9, 42, 68, 21, 24, 159, 4],\n",
              " [2, 4, 14, 5, 157, 6, 39, 73, 158, 9, 42, 68, 21, 24, 159, 4, 70],\n",
              " [2, 4, 14, 5, 157, 6, 39, 73, 158, 9, 42, 68, 21, 24, 159, 4, 70, 2],\n",
              " [2, 4, 14, 5, 157, 6, 39, 73, 158, 9, 42, 68, 21, 24, 159, 4, 70, 2, 19],\n",
              " [2, 4, 14, 5, 157, 6, 39, 73, 158, 9, 42, 68, 21, 24, 159, 4, 70, 2, 19, 6],\n",
              " [2,\n",
              "  4,\n",
              "  14,\n",
              "  5,\n",
              "  157,\n",
              "  6,\n",
              "  39,\n",
              "  73,\n",
              "  158,\n",
              "  9,\n",
              "  42,\n",
              "  68,\n",
              "  21,\n",
              "  24,\n",
              "  159,\n",
              "  4,\n",
              "  70,\n",
              "  2,\n",
              "  19,\n",
              "  6,\n",
              "  74],\n",
              " [2,\n",
              "  4,\n",
              "  14,\n",
              "  5,\n",
              "  157,\n",
              "  6,\n",
              "  39,\n",
              "  73,\n",
              "  158,\n",
              "  9,\n",
              "  42,\n",
              "  68,\n",
              "  21,\n",
              "  24,\n",
              "  159,\n",
              "  4,\n",
              "  70,\n",
              "  2,\n",
              "  19,\n",
              "  6,\n",
              "  74,\n",
              "  44],\n",
              " [2,\n",
              "  4,\n",
              "  14,\n",
              "  5,\n",
              "  157,\n",
              "  6,\n",
              "  39,\n",
              "  73,\n",
              "  158,\n",
              "  9,\n",
              "  42,\n",
              "  68,\n",
              "  21,\n",
              "  24,\n",
              "  159,\n",
              "  4,\n",
              "  70,\n",
              "  2,\n",
              "  19,\n",
              "  6,\n",
              "  74,\n",
              "  44,\n",
              "  74],\n",
              " [2,\n",
              "  4,\n",
              "  14,\n",
              "  5,\n",
              "  157,\n",
              "  6,\n",
              "  39,\n",
              "  73,\n",
              "  158,\n",
              "  9,\n",
              "  42,\n",
              "  68,\n",
              "  21,\n",
              "  24,\n",
              "  159,\n",
              "  4,\n",
              "  70,\n",
              "  2,\n",
              "  19,\n",
              "  6,\n",
              "  74,\n",
              "  44,\n",
              "  74,\n",
              "  32],\n",
              " [2,\n",
              "  4,\n",
              "  14,\n",
              "  5,\n",
              "  157,\n",
              "  6,\n",
              "  39,\n",
              "  73,\n",
              "  158,\n",
              "  9,\n",
              "  42,\n",
              "  68,\n",
              "  21,\n",
              "  24,\n",
              "  159,\n",
              "  4,\n",
              "  70,\n",
              "  2,\n",
              "  19,\n",
              "  6,\n",
              "  74,\n",
              "  44,\n",
              "  74,\n",
              "  32,\n",
              "  75],\n",
              " [2,\n",
              "  4,\n",
              "  14,\n",
              "  5,\n",
              "  157,\n",
              "  6,\n",
              "  39,\n",
              "  73,\n",
              "  158,\n",
              "  9,\n",
              "  42,\n",
              "  68,\n",
              "  21,\n",
              "  24,\n",
              "  159,\n",
              "  4,\n",
              "  70,\n",
              "  2,\n",
              "  19,\n",
              "  6,\n",
              "  74,\n",
              "  44,\n",
              "  74,\n",
              "  32,\n",
              "  75,\n",
              "  16],\n",
              " [22, 3],\n",
              " [22, 3, 30],\n",
              " [22, 3, 30, 1],\n",
              " [22, 3, 30, 1, 10],\n",
              " [22, 3, 30, 1, 10, 63],\n",
              " [22, 3, 30, 1, 10, 63, 8],\n",
              " [22, 3, 30, 1, 10, 63, 8, 3],\n",
              " [22, 3, 30, 1, 10, 63, 8, 3, 160],\n",
              " [22, 3, 30, 1, 10, 63, 8, 3, 160, 161],\n",
              " [22, 3, 30, 1, 10, 63, 8, 3, 160, 161, 31],\n",
              " [22, 3, 30, 1, 10, 63, 8, 3, 160, 161, 31, 76],\n",
              " [22, 3, 30, 1, 10, 63, 8, 3, 160, 161, 31, 76, 162],\n",
              " [23, 163],\n",
              " [23, 163, 164],\n",
              " [23, 163, 164, 31],\n",
              " [23, 163, 164, 31, 76],\n",
              " [23, 163, 164, 31, 76, 32],\n",
              " [23, 163, 164, 31, 76, 32, 9],\n",
              " [23, 163, 164, 31, 76, 32, 9, 1],\n",
              " [23, 163, 164, 31, 76, 32, 9, 1, 32],\n",
              " [23, 163, 164, 31, 76, 32, 9, 1, 32, 75],\n",
              " [23, 163, 164, 31, 76, 32, 9, 1, 32, 75, 39],\n",
              " [23, 163, 164, 31, 76, 32, 9, 1, 32, 75, 39, 73],\n",
              " [77, 21],\n",
              " [77, 21, 165],\n",
              " [77, 21, 165, 166],\n",
              " [77, 21, 165, 166, 167],\n",
              " [77, 21, 165, 166, 167, 168],\n",
              " [15, 11],\n",
              " [15, 11, 1],\n",
              " [15, 11, 1, 169],\n",
              " [15, 11, 1, 169, 5],\n",
              " [15, 11, 1, 169, 5, 38],\n",
              " [15, 11, 1, 169, 5, 38, 1],\n",
              " [15, 11, 1, 169, 5, 38, 1, 77],\n",
              " [170, 37],\n",
              " [170, 37, 171],\n",
              " [170, 37, 171, 172],\n",
              " [2, 14],\n",
              " [2, 14, 5],\n",
              " [2, 14, 5, 65],\n",
              " [2, 14, 5, 65, 1],\n",
              " [2, 14, 5, 65, 1, 173],\n",
              " [2, 14, 5, 65, 1, 173, 174],\n",
              " [2, 14],\n",
              " [2, 14, 5],\n",
              " [2, 14, 5, 175],\n",
              " [2, 14, 5, 175, 12],\n",
              " [2, 14, 5, 175, 12, 1],\n",
              " [2, 14, 5, 175, 12, 1, 17],\n",
              " [2, 14, 5, 175, 12, 1, 17, 176],\n",
              " [177, 178],\n",
              " [177, 178, 13],\n",
              " [179, 180],\n",
              " [179, 180, 13],\n",
              " [13, 27],\n",
              " [13, 27, 181],\n",
              " [13, 27, 181, 182],\n",
              " [183, 44],\n",
              " [183, 44, 184],\n",
              " [183, 44, 184, 185],\n",
              " [183, 44, 184, 185, 186]]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max([len(x) for x in input_sequences])"
      ],
      "metadata": {
        "id": "wJFeNGidHKz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euizERKEHK2v",
        "outputId": "3b6cae51-9013-4a09-e745-e372f4b0a52d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "pad_input_sequence = pad_sequences(input_sequences, maxlen = max_len, padding='pre')"
      ],
      "metadata": {
        "id": "ybsG3YkBHK54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pad_input_sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xot6ahnHK9B",
        "outputId": "00325668-c61a-41d6-e604-04179809cd38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,  45,   1],\n",
              "       [  0,   0,   0, ...,  45,   1,  10],\n",
              "       [  0,   0,   0, ...,   0,  15,  11],\n",
              "       ...,\n",
              "       [  0,   0,   0, ..., 183,  44, 184],\n",
              "       [  0,   0,   0, ...,  44, 184, 185],\n",
              "       [  0,   0,   0, ..., 184, 185, 186]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = pad_input_sequence[:,:-1]\n",
        "y = pad_input_sequence[:, -1]"
      ],
      "metadata": {
        "id": "OgIN93MxI_uL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obiJBbHfJQoQ",
        "outputId": "1a4d41fd-6cfb-4101-d5f9-bad50b1feb1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(403, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_zTmkJuJZcW",
        "outputId": "55bc49ff-4c8a-48a4-f097-d825fc13f758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(403,)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "y = to_categorical(y , num_classes=200)"
      ],
      "metadata": {
        "id": "Rz3_gcvzJdOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBvicHagJQrg",
        "outputId": "ca356c63-9954-4934-e316-fa3b46221025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(403, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building LSTM Model"
      ],
      "metadata": {
        "id": "lgBzCse4KJpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "from keras.models import Model\n",
        "from keras import Input"
      ],
      "metadata": {
        "id": "M961iQj_KDoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "timesteps = 40\n",
        "features = 3\n",
        "LSTMoutputdimention = 2\n",
        "\n",
        "input = Input(shape=(timesteps, features))\n",
        "output = LSTM(LSTMoutputdimention)(input)\n",
        "model_LSTM = Model(inputs=input, outputs=output)\n",
        "model_LSTM.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0oxGNOou1Js",
        "outputId": "dfaa3948-c474-4bfe-d48d-ddbb8bf7202e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 40, 3)]           0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 2)                 48        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 48 (192.00 Byte)\n",
            "Trainable params: 48 (192.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(150, input_shape=(timesteps, features)))"
      ],
      "metadata": {
        "id": "qiaOdKAswS8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(200, 100, input_length=25))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(200, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHellAM6KTTp",
        "outputId": "24919a50-6844-4ede-b868-e7049c60bd6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 25, 100)           20000     \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 150)               150600    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 200)               30200     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 200800 (784.38 KB)\n",
            "Trainable params: 200800 (784.38 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zY0ucGLhuyN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "4*((150+100)*150+150)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BS2Y1d-OssAp",
        "outputId": "2bf7e467-3e67-4fbd-eb44-8eedd173a4da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150600"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "4*((150+25)*150+150)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTeA5Qt-rwHb",
        "outputId": "d7418ebc-2108-432e-c310-62a05ae1557a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "105600"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x, y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Scqr87SvK_BP",
        "outputId": "65fea2f2-6d5d-4d90-acbc-0ecbcddd69d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "13/13 [==============================] - 9s 158ms/step - loss: 5.2617 - accuracy: 0.0769\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 1s 93ms/step - loss: 4.8997 - accuracy: 0.0943\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 1s 43ms/step - loss: 4.7367 - accuracy: 0.0943\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 1s 42ms/step - loss: 4.6889 - accuracy: 0.0943\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 4.6550 - accuracy: 0.0943\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 0s 31ms/step - loss: 4.6367 - accuracy: 0.0943\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 1s 43ms/step - loss: 4.5964 - accuracy: 0.0943\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 4.5556 - accuracy: 0.0943\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 1s 56ms/step - loss: 4.4981 - accuracy: 0.0943\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 4.4098 - accuracy: 0.0993\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 4.3050 - accuracy: 0.1141\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 0s 27ms/step - loss: 4.1618 - accuracy: 0.1042\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 0s 27ms/step - loss: 4.0211 - accuracy: 0.1414\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 0s 28ms/step - loss: 3.8474 - accuracy: 0.1638\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 0s 8ms/step - loss: 3.6882 - accuracy: 0.2035\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 0s 30ms/step - loss: 3.5388 - accuracy: 0.2382\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 0s 28ms/step - loss: 3.3552 - accuracy: 0.2506\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 1s 41ms/step - loss: 3.2027 - accuracy: 0.3027\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 3.0414 - accuracy: 0.3102\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 2.8932 - accuracy: 0.3524\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 2.7393 - accuracy: 0.3722\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 2.5872 - accuracy: 0.3945\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 2.4695 - accuracy: 0.4243\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 2.3394 - accuracy: 0.4566\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 2.2145 - accuracy: 0.4913\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 2.1051 - accuracy: 0.5360\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 1.9946 - accuracy: 0.5757\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 1.8771 - accuracy: 0.5980\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 1.7734 - accuracy: 0.6352\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 1.6699 - accuracy: 0.6650\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 1.5943 - accuracy: 0.6799\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.5025 - accuracy: 0.7221\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 1.4097 - accuracy: 0.7519\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 1.3374 - accuracy: 0.7742\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 1.2714 - accuracy: 0.7816\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 1.2006 - accuracy: 0.7940\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 1.1450 - accuracy: 0.8040\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 1.0815 - accuracy: 0.8313\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 1.0314 - accuracy: 0.8263\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.9744 - accuracy: 0.8561\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.9217 - accuracy: 0.8734\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.8701 - accuracy: 0.8685\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.8247 - accuracy: 0.8809\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.7830 - accuracy: 0.8834\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.7432 - accuracy: 0.9082\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.7069 - accuracy: 0.9057\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.6783 - accuracy: 0.9007\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.6445 - accuracy: 0.9082\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.6134 - accuracy: 0.9181\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.5856 - accuracy: 0.9206\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.5613 - accuracy: 0.9231\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.5373 - accuracy: 0.9305\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.5142 - accuracy: 0.9355\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4905 - accuracy: 0.9330\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4740 - accuracy: 0.9330\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4538 - accuracy: 0.9380\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4391 - accuracy: 0.9330\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4166 - accuracy: 0.9380\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.4035 - accuracy: 0.9380\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.3924 - accuracy: 0.9380\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.3787 - accuracy: 0.9404\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.3655 - accuracy: 0.9380\n",
            "Epoch 63/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.3531 - accuracy: 0.9355\n",
            "Epoch 64/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.3404 - accuracy: 0.9380\n",
            "Epoch 65/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.3321 - accuracy: 0.9380\n",
            "Epoch 66/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.3215 - accuracy: 0.9380\n",
            "Epoch 67/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.3129 - accuracy: 0.9305\n",
            "Epoch 68/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.3020 - accuracy: 0.9404\n",
            "Epoch 69/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.2938 - accuracy: 0.9404\n",
            "Epoch 70/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.2865 - accuracy: 0.9380\n",
            "Epoch 71/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2797 - accuracy: 0.9404\n",
            "Epoch 72/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2737 - accuracy: 0.9429\n",
            "Epoch 73/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2664 - accuracy: 0.9429\n",
            "Epoch 74/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2571 - accuracy: 0.9404\n",
            "Epoch 75/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2526 - accuracy: 0.9404\n",
            "Epoch 76/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2501 - accuracy: 0.9429\n",
            "Epoch 77/100\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.2452 - accuracy: 0.9404\n",
            "Epoch 78/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2371 - accuracy: 0.9404\n",
            "Epoch 79/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2338 - accuracy: 0.9380\n",
            "Epoch 80/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2281 - accuracy: 0.9454\n",
            "Epoch 81/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2234 - accuracy: 0.9429\n",
            "Epoch 82/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2205 - accuracy: 0.9404\n",
            "Epoch 83/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2167 - accuracy: 0.9429\n",
            "Epoch 84/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2126 - accuracy: 0.9404\n",
            "Epoch 85/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2087 - accuracy: 0.9380\n",
            "Epoch 86/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2080 - accuracy: 0.9404\n",
            "Epoch 87/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2025 - accuracy: 0.9404\n",
            "Epoch 88/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.2010 - accuracy: 0.9454\n",
            "Epoch 89/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1973 - accuracy: 0.9429\n",
            "Epoch 90/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1946 - accuracy: 0.9429\n",
            "Epoch 91/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1903 - accuracy: 0.9454\n",
            "Epoch 92/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1927 - accuracy: 0.9330\n",
            "Epoch 93/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1897 - accuracy: 0.9429\n",
            "Epoch 94/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1844 - accuracy: 0.9355\n",
            "Epoch 95/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1816 - accuracy: 0.9355\n",
            "Epoch 96/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1803 - accuracy: 0.9404\n",
            "Epoch 97/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1784 - accuracy: 0.9429\n",
            "Epoch 98/100\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 0.1742 - accuracy: 0.9454\n",
            "Epoch 99/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1740 - accuracy: 0.9404\n",
            "Epoch 100/100\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 0.1751 - accuracy: 0.9454\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c70f7f75db0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict the next word\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "text =\"Placement\"\n",
        "\n",
        "for i in range(15):\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "  # padding\n",
        "  padded_token_text = pad_sequences([token_text], maxlen=25, padding='pre')\n",
        "  # predict\n",
        "  pos = np.argmax(model.predict(padded_token_text))\n",
        "\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index==pos:\n",
        "      text = text +\" \" + word\n",
        "      print(text)\n",
        "      time.sleep(2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJpH3mktJQuj",
        "outputId": "cbc6811c-35df-4469-b932-a424fe0ed007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 348ms/step\n",
            "Placement deep\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Placement deep learning\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Placement deep learning with\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Placement deep learning with nlp\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Placement deep learning with nlp be\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Placement deep learning with nlp be a\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Placement deep learning with nlp be a part\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Placement deep learning with nlp be a part of\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Placement deep learning with nlp be a part of this\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Placement deep learning with nlp be a part of this program\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Placement deep learning with nlp be a part of this program program\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Placement deep learning with nlp be a part of this program program this\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Placement deep learning with nlp be a part of this program program this middle\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Placement deep learning with nlp be a part of this program program this middle will\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "Placement deep learning with nlp be a part of this program program this middle will i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "38RyPOJlJQxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VhyY6ngGJQ0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep_RNN/Deep_LSTM/Deep_GRU"
      ],
      "metadata": {
        "id": "JZYUPmVy2rND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, SimpleRNN, Dense, LSTM, GRU, Bidirectional"
      ],
      "metadata": {
        "id": "uNEL4iL0JQ3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "(x_train, y_train),(x_test, y_test) = imdb.load_data(num_words=10000)\n",
        "x_train = pad_sequences(x_train, maxlen=100)\n",
        "x_test = pad_sequences(x_test, maxlen=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRTvuth-2vlQ",
        "outputId": "56b3a226-22c9-43bb-e5e2-8b4ac7733e35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep RNN"
      ],
      "metadata": {
        "id": "FsXsFFgo3yWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Sequential([\n",
        "    Embedding(10000, 32, input_length=100),\n",
        "    SimpleRNN(5, return_sequences=True),\n",
        "    SimpleRNN(5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model1.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "za0CHEwi3wJq",
        "outputId": "6a3018c1-53c0-4fdb-de09-46b3e37c5690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 100, 32)           320000    \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 100, 5)            190       \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 5)                 55        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320251 (1.22 MB)\n",
            "Trainable params: 320251 (1.22 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep LSTM"
      ],
      "metadata": {
        "id": "3D6eE8al5TRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential([\n",
        "    Embedding(10000, 32, input_length=100),\n",
        "    LSTM(5, return_sequences=True),\n",
        "    LSTM(5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yDOdQwm2vpg",
        "outputId": "419db0ab-79ba-4dd6-eb68-eafd4dfdfca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 100, 32)           320000    \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 100, 5)            760       \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 5)                 220       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320986 (1.22 MB)\n",
            "Trainable params: 320986 (1.22 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep GRU"
      ],
      "metadata": {
        "id": "zy8QMHKz5czv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = Sequential([\n",
        "    Embedding(10000, 32, input_length=100),\n",
        "    GRU(5, return_sequences=True),\n",
        "    GRU(5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiQG-1R72vsp",
        "outputId": "0666cc88-ee91-459f-afe9-160ae19790a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 100, 32)           320000    \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 100, 5)            585       \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 5)                 180       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320771 (1.22 MB)\n",
            "Trainable params: 320771 (1.22 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "UiVvYA8r2vv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model3.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyGnaX0m2vy8",
        "outputId": "782b520b-76ec-49ab-f43d-cce6cbed2575"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "625/625 [==============================] - 36s 51ms/step - loss: 0.4927 - accuracy: 0.7529 - val_loss: 0.3835 - val_accuracy: 0.8380\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 10s 17ms/step - loss: 0.2947 - accuracy: 0.8830 - val_loss: 0.3792 - val_accuracy: 0.8416\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 9s 15ms/step - loss: 0.2175 - accuracy: 0.9211 - val_loss: 0.3904 - val_accuracy: 0.8320\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.1655 - accuracy: 0.9439 - val_loss: 0.4403 - val_accuracy: 0.8372\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.1269 - accuracy: 0.9585 - val_loss: 0.4705 - val_accuracy: 0.8326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bi-Directional LSTM"
      ],
      "metadata": {
        "id": "edR4ZHmeHB0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential([\n",
        "    Embedding(10000, 32, input_length=100),\n",
        "    Bidirectional(SimpleRNN(5, return_sequences=True)),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model2.summary()"
      ],
      "metadata": {
        "id": "g0O6SYpvHttp",
        "outputId": "d1f81677-8588-4fa4-a883-4922b22ad2a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 100, 32)           320000    \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 100, 10)           380       \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 100, 1)            11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320391 (1.22 MB)\n",
            "Trainable params: 320391 (1.22 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential([\n",
        "    Embedding(10000, 32, input_length=100),\n",
        "    Bidirectional(LSTM(5, return_sequences=True)),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00Zqej-i2v6S",
        "outputId": "633883a1-6d20-41f6-d32d-451fc5bfdd45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 100, 32)           320000    \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 100, 10)           1520      \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 100, 1)            11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 321531 (1.23 MB)\n",
            "Trainable params: 321531 (1.23 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential([\n",
        "    Embedding(10000, 32, input_length=100),\n",
        "    Bidirectional(GRU(5, return_sequences=True)),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model2.summary()"
      ],
      "metadata": {
        "id": "SlndIsRqHwt_",
        "outputId": "adb50013-cab3-411b-e70b-3bc4760b810a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, 100, 32)           320000    \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirecti  (None, 100, 10)           1170      \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 100, 1)            11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 321181 (1.23 MB)\n",
            "Trainable params: 321181 (1.23 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history = model3.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "id": "AwPMzEPe2v9C",
        "outputId": "acd21740-0565-4281-9343-12e3139440e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 26s 36ms/step - loss: 0.0399 - accuracy: 0.9889 - val_loss: 0.7372 - val_accuracy: 0.8230\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 9s 14ms/step - loss: 0.0262 - accuracy: 0.9934 - val_loss: 0.7767 - val_accuracy: 0.8236\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 9s 14ms/step - loss: 0.0205 - accuracy: 0.9955 - val_loss: 0.8223 - val_accuracy: 0.8210\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.0199 - accuracy: 0.9952 - val_loss: 0.8814 - val_accuracy: 0.8250\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 7s 12ms/step - loss: 0.0176 - accuracy: 0.9959 - val_loss: 0.9016 - val_accuracy: 0.8170\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.0175 - accuracy: 0.9959 - val_loss: 0.8871 - val_accuracy: 0.8194\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 7s 12ms/step - loss: 0.0171 - accuracy: 0.9955 - val_loss: 0.9040 - val_accuracy: 0.8136\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 7s 12ms/step - loss: 0.0138 - accuracy: 0.9967 - val_loss: 0.9408 - val_accuracy: 0.8138\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.0110 - accuracy: 0.9974 - val_loss: 1.0142 - val_accuracy: 0.8124\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.0073 - accuracy: 0.9984 - val_loss: 1.0232 - val_accuracy: 0.8106\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "inm-6Tnw2wLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yLwNihzf2wO2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}